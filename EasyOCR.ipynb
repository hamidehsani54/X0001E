{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVW1LPDOpcCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c8488b-6ba8-40aa-f044-3ba4827ada7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless==4.5.4.60\n",
            "  Downloading opencv_python_headless-4.5.4.60-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless==4.5.4.60) (1.25.2)\n",
            "Installing collected packages: opencv-python-headless\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.9.0.80\n",
            "    Uninstalling opencv-python-headless-4.9.0.80:\n",
            "      Successfully uninstalled opencv-python-headless-4.9.0.80\n",
            "Successfully installed opencv-python-headless-4.5.4.60\n",
            "Collecting easyocr==1.6.2\n",
            "  Downloading easyocr-1.6.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr==1.6.2) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr==1.6.2) (0.18.0+cu121)\n",
            "Requirement already satisfied: opencv-python-headless<=4.5.4.60 in /usr/local/lib/python3.10/dist-packages (from easyocr==1.6.2) (4.5.4.60)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr==1.6.2) (1.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr==1.6.2) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr==1.6.2) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr==1.6.2) (0.19.3)\n",
            "Collecting python-bidi (from easyocr==1.6.2)\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr==1.6.2) (6.0.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr==1.6.2) (2.0.4)\n",
            "Collecting pyclipper (from easyocr==1.6.2)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from easyocr==1.6.2)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr==1.6.2) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr==1.6.2) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr==1.6.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr==1.6.2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr==1.6.2) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr==1.6.2) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->easyocr==1.6.2)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->easyocr==1.6.2)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->easyocr==1.6.2)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->easyocr==1.6.2)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->easyocr==1.6.2)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->easyocr==1.6.2)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->easyocr==1.6.2)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->easyocr==1.6.2)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->easyocr==1.6.2)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->easyocr==1.6.2)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->easyocr==1.6.2)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr==1.6.2) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->easyocr==1.6.2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-bidi->easyocr==1.6.2) (1.16.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr==1.6.2) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr==1.6.2) (2024.5.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr==1.6.2) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr==1.6.2) (24.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr==1.6.2) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr==1.6.2) (1.3.0)\n",
            "Installing collected packages: pyclipper, ninja, python-bidi, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, easyocr\n",
            "Successfully installed easyocr-1.6.2 ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pyclipper-1.3.0.post5 python-bidi-0.4.2\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (9.4.0)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.4 [186 kB]\n",
            "Fetched 186 kB in 2s (119 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.4) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.4) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.4-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jiwer\n",
            "  Downloading jiwer-3.0.4-py3-none-any.whl (21 kB)\n",
            "Collecting PyMuPDFb==1.24.3 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
            "  Downloading rapidfuzz-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, PyMuPDFb, PyMuPDF, jiwer\n",
            "Successfully installed PyMuPDF-1.24.4 PyMuPDFb-1.24.3 jiwer-3.0.4 rapidfuzz-3.9.1\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless==4.5.4.60\n",
        "!pip install easyocr==1.6.2\n",
        "!pip install pdf2image\n",
        "!apt-get install poppler-utils\n",
        "!pip install PyMuPDF jiwer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if you need to convert the pdf file to txt file\n",
        "!pip install pdfminer.six"
      ],
      "metadata": {
        "id": "8beQG9xaOJSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29130153-50db-4017-92de-1844d3e6fb83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/5.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m4.3/5.6 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (42.0.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Installing collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20231228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Trying to controll that the extracted text looks the same way as in image\n",
        "\n",
        "import easyocr\n",
        "import numpy as np\n",
        "from pdf2image import convert_from_path\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "pdf_path = \"2.pdf\"\n",
        "\n",
        "def sort_and_group_texts(texts):\n",
        "    # Sort texts based on the top-left y-coordinate, then by x-coordinate\n",
        "    sorted_texts = sorted(texts, key=lambda x: (x[0][0][1], x[0][0][0]))\n",
        "\n",
        "    # Group texts by rows based on y-coordinate\n",
        "    rows = []\n",
        "    current_row = []\n",
        "    last_y = None\n",
        "    y_threshold = 10  # Adjust as necessary for your documents\n",
        "\n",
        "    for bbox, text, _ in sorted_texts:\n",
        "        top_left = bbox[0]\n",
        "        y = top_left[1]\n",
        "\n",
        "        if last_y is not None and abs(y - last_y) > y_threshold:\n",
        "            # New row\n",
        "            rows.append(current_row)\n",
        "            current_row = []\n",
        "\n",
        "        current_row.append((bbox, text))\n",
        "        last_y = y\n",
        "\n",
        "    # Add the last row if it's not empty\n",
        "    if current_row:\n",
        "        rows.append(current_row)\n",
        "\n",
        "    return rows\n",
        "\n",
        "try:\n",
        "    reader = easyocr.Reader(['sv'])\n",
        "    images = convert_from_path(pdf_path)\n",
        "\n",
        "    all_rows = []\n",
        "\n",
        "    for i, image in enumerate(images):\n",
        "        image_np = np.array(image)\n",
        "        image_rgb = image_np[:, :, ::-1].copy()  # Convert BGR to RGB\n",
        "        detected_texts = reader.readtext(image_rgb, detail=1)  # Ensure detail is True for bbox\n",
        "        rows = sort_and_group_texts(detected_texts)\n",
        "        all_rows.extend(rows)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "root = ET.Element(\"root\")\n",
        "page = ET.SubElement(root, \"page\")\n",
        "\n",
        "for row in all_rows:\n",
        "    row_element = ET.SubElement(page, \"row\")\n",
        "    for bbox, text in row:\n",
        "        item = ET.SubElement(row_element, \"item\")\n",
        "        item.text = text\n",
        "        item.set('bbox', str(bbox))\n",
        "tree = ET.ElementTree(root)\n",
        "tree.write(\"output.xml\")\n",
        "print(\"The process has been done, see your directory!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEf373QhFW0N",
        "outputId": "e37a5966-c348-45a6-9028-15966d140fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The process has been done, see your directory!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate CER and WER for each PDF\n",
        "import os\n",
        "import easyocr\n",
        "from pdf2image import convert_from_path\n",
        "import numpy as np\n",
        "import re\n",
        "from jiwer import wer, cer\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Remove invalid XML characters from the text.\n",
        "    \"\"\"\n",
        "    invalid_xml_chars = re.compile(u'[\\u0000-\\u0008\\u000B-\\u000C\\u000E-\\u001F]')\n",
        "    return invalid_xml_chars.sub('', text)\n",
        "\n",
        "directory_path = 'text/'\n",
        "\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Loop through all files in the directory\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith('.pdf'):\n",
        "        pdf_path = os.path.join(directory_path, filename)\n",
        "        ground_truth_path = os.path.join(directory_path, filename.replace('.pdf', '.txt'))\n",
        "\n",
        "        # Convert PDF to images\n",
        "        images = convert_from_path(pdf_path)\n",
        "\n",
        "        # Initialize variable to hold all OCR output text\n",
        "        all_text = []\n",
        "\n",
        "        # Perform OCR on each page\n",
        "        for image in images:\n",
        "            # Convert the PIL Image to a NumPy array\n",
        "            np_image = np.array(image)\n",
        "\n",
        "            # Use EasyOCR to read text from the image\n",
        "            results = reader.readtext(np_image, paragraph=True)  # Using paragraph mode to better format text\n",
        "            text = ' '.join([result[1] for result in results])\n",
        "            clean_text_data = clean_text(text)\n",
        "            all_text.append(clean_text_data)\n",
        "\n",
        "        # Concatenate all OCR output text into a single string\n",
        "        ocr_output_text = '\\n'.join(all_text)\n",
        "\n",
        "        # Load ground truth text\n",
        "        with open(ground_truth_path, 'r', encoding='utf-8') as gt_file:\n",
        "            ground_truth_text = gt_file.read()\n",
        "\n",
        "        # Calculate WER and CER\n",
        "        calculated_wer = wer(ground_truth_text, ocr_output_text)\n",
        "        calculated_cer = cer(ground_truth_text, ocr_output_text)\n",
        "\n",
        "        print(f\"Results for {filename}:\")\n",
        "        print(f\"\\nWER: {calculated_wer:.2f}\")\n",
        "        print(f\"CER: {calculated_cer:.2f}\\n\")\n"
      ],
      "metadata": {
        "id": "0ImzH_NIqZf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "94910f90-1671-4c0b-d77c-89a89f1e269a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for 2EDEPZ4VHTLPTWSZR6FAVUJ3B2ZVSIPS.pdf:\n",
            "\n",
            "WER: 0.21\n",
            "CER: 0.08\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert pdf to txt file\n",
        "import os\n",
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "def convert_pdf_to_txt(pdf_path, txt_path):\n",
        "    \"\"\"\n",
        "    Convert a PDF file to a text file using pdfminer.six.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        text = extract_text(pdf_path)\n",
        "        with open(txt_path, 'w', encoding='utf-8') as txt_file:\n",
        "            txt_file.write(text)\n",
        "        print(f\"Converted {pdf_path} to {txt_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting {pdf_path}: {str(e)}\")\n",
        "\n",
        "def convert_pdfs_in_directory(directory):\n",
        "    \"\"\"\n",
        "    Convert all PDF files to text files.\n",
        "    \"\"\"\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.lower().endswith('.pdf'):\n",
        "            pdf_path = os.path.join(directory, filename)\n",
        "            txt_path = os.path.join(directory, filename.replace('.pdf', '.txt'))\n",
        "            convert_pdf_to_txt(pdf_path, txt_path)\n",
        "\n",
        "def main():\n",
        "    directory_path = 'large/'\n",
        "    convert_pdfs_in_directory(directory_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-Iv1CS-N8eU",
        "outputId": "2ea4a190-492b-4b60-ecb0-ef9698903e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted large/101 pages.pdf to large/101 pages.txt\n",
            "Converted large/255 pages.pdf to large/255 pages.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import easyocr\n",
        "from pdf2image import convert_from_path\n",
        "import numpy as np\n",
        "import re\n",
        "from jiwer import wer, cer\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Remove invalid XML characters from the text.\n",
        "    \"\"\"\n",
        "    invalid_xml_chars = re.compile(u'[\\u0000-\\u0008\\u000B-\\u000C\\u000E-\\u001F]')\n",
        "    return invalid_xml_chars.sub('', text)\n",
        "\n",
        "directory_path = 'table/'\n",
        "\n",
        "reader = easyocr.Reader(['en'])\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith('.pdf'):\n",
        "        pdf_path = os.path.join(directory_path, filename)\n",
        "        ground_truth_path = os.path.join(directory_path, filename.replace('.pdf', '.txt'))\n",
        "\n",
        "        # Convert PDF to images\n",
        "        images = convert_from_path(pdf_path)\n",
        "\n",
        "        # Initialize variable to hold all OCR output text\n",
        "        all_text = []\n",
        "\n",
        "        # Perform OCR on each page\n",
        "        for image in images:\n",
        "            # Convert the PIL Image to a NumPy array\n",
        "            np_image = np.array(image)\n",
        "            results = reader.readtext(np_image, paragraph=True)\n",
        "            text = ' '.join([result[1] for result in results])\n",
        "            clean_text_data = clean_text(text)\n",
        "            all_text.append(clean_text_data)\n",
        "\n",
        "        ocr_output_text = '\\n'.join(all_text)\n",
        "\n",
        "        # Load ground truth text\n",
        "        with open(ground_truth_path, 'r', encoding='utf-8') as gt_file:\n",
        "            ground_truth_text = gt_file.read()\n",
        "\n",
        "        # Calculate WER and CER\n",
        "        calculated_wer = wer(ground_truth_text, ocr_output_text)\n",
        "        calculated_cer = cer(ground_truth_text, ocr_output_text)\n",
        "\n",
        "        print(f\"Results for {filename}:\")\n",
        "        print(f\"\\nWER: {calculated_wer:.2f}\")\n",
        "        print(f\"CER: {calculated_cer:.2f}\\n\")\n"
      ],
      "metadata": {
        "id": "WfB7WJsEO5Aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip table-filename.zip"
      ],
      "metadata": {
        "id": "UuZC921I7gF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r text-filename.zip text"
      ],
      "metadata": {
        "id": "wNSny50B7m_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Metadata Extraction\n",
        "\n",
        "import easyocr\n",
        "import numpy as np\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "from pdf2image import convert_from_path\n",
        "import re\n",
        "\n",
        "def preprocess_image(image):\n",
        "    \"\"\"Apply preprocessing steps to improve OCR accuracy.\"\"\"\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
        "    thresh_image = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "    kernel = np.ones((2,2), np.uint8)\n",
        "    dilated_image = cv2.dilate(thresh_image, kernel, iterations=1)\n",
        "    return dilated_image\n",
        "\n",
        "def extract_text_to_xml(pdf_path, xml_path):\n",
        "    \"\"\"Extracts text from images and saves to an XML file.\"\"\"\n",
        "    reader = easyocr.Reader(['sv'], recog_network='latin_g2')\n",
        "    images = convert_from_path(pdf_path)\n",
        "    root = ET.Element(\"root\")\n",
        "\n",
        "    for image in images:\n",
        "        image_np = np.array(image)\n",
        "        preprocessed_image = preprocess_image(image_np)\n",
        "        results = reader.readtext(preprocessed_image, detail=1, paragraph=False)\n",
        "\n",
        "        for bbox, text, confidence in results:\n",
        "            item = ET.SubElement(root, \"item\")\n",
        "            item.set('bbox', str(bbox))\n",
        "            item.set('confidence', str(confidence))\n",
        "            item.text = text\n",
        "\n",
        "    tree = ET.ElementTree(root)\n",
        "    tree.write(xml_path, encoding=\"utf-8\", xml_declaration=True)\n",
        "\n",
        "def extract_specific_info_from_xml(xml_path, keywords, text_limits):\n",
        "    \"\"\"Extracts specific information based on predefined keywords from an XML file.\"\"\"\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "    items = list(root.findall('item'))\n",
        "    pairs = {}\n",
        "    current_key = None\n",
        "    current_text = []\n",
        "    current_limit = None\n",
        "\n",
        "    normalized_keywords = {keyword.lower(): keyword for keyword in keywords}\n",
        "\n",
        "    for item in items:\n",
        "        text = item.text or \"\"\n",
        "        normalized_text = text.lower().strip()\n",
        "\n",
        "        if any(normalized_text.startswith(keyword) for keyword in normalized_keywords):\n",
        "            if current_key:\n",
        "                formatted_text = ' '.join(current_text).strip()\n",
        "                if current_limit is not None:\n",
        "                    formatted_text = formatted_text[:current_limit]\n",
        "                pairs[current_key] = formatted_text\n",
        "            current_key = normalized_keywords.get(normalized_text, text.strip())\n",
        "            current_text = []\n",
        "            current_limit = text_limits.get(current_key, None)\n",
        "        elif current_key:\n",
        "            current_text.append(text.strip())\n",
        "\n",
        "    if current_key:\n",
        "        formatted_text = ' '.join(current_text).strip()\n",
        "        if current_limit is not None:\n",
        "            formatted_text = formatted_text[:current_limit]\n",
        "        pairs[current_key] = formatted_text\n",
        "\n",
        "    return pairs\n",
        "\n",
        "def main():\n",
        "    pdf_path = \"3.pdf\"\n",
        "    xml_path = \"output.xml\"\n",
        "    keywords = [\"Fastighetsägare\", \"Namn\", \"Postnr och ort\", \"Fastighetsbeteckning\", \"Anläggare av ledning\"]\n",
        "    text_limits = {\"Anläggare av ledning\": 41}  # Limit text for last keyword\n",
        "\n",
        "    extract_text_to_xml(pdf_path, xml_path)  # Extract text and save to XML\n",
        "    info = extract_specific_info_from_xml(xml_path, keywords, text_limits)  # Process and display information\n",
        "\n",
        "    for key in keywords:\n",
        "        value = info.get(key, \"\")  # Use get to handle missing keywords gracefully\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "9q9c6pz_ODuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate the time duration\n",
        "import easyocr\n",
        "import numpy as np\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "from pdf2image import convert_from_path\n",
        "import time\n",
        "def preprocess_image(image):\n",
        "    \"\"\"Apply preprocessing steps to improve OCR accuracy.\"\"\"\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
        "    thresh_image = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "    kernel = np.ones((2,2), np.uint8)\n",
        "    dilated_image = cv2.dilate(thresh_image, kernel, iterations=1)\n",
        "    return dilated_image\n",
        "\n",
        "def extract_text_to_xml(pdf_path, xml_path):\n",
        "    \"\"\"Extracts text from images and saves to an XML file.\"\"\"\n",
        "    reader = easyocr.Reader(['sv'], recog_network='latin_g2')\n",
        "    images = convert_from_path(pdf_path)\n",
        "    root = ET.Element(\"root\")\n",
        "\n",
        "    for image in images:\n",
        "        image_np = np.array(image)\n",
        "        preprocessed_image = preprocess_image(image_np)\n",
        "        results = reader.readtext(preprocessed_image, detail=1, paragraph=False)\n",
        "\n",
        "        for bbox, text, confidence in results:\n",
        "            item = ET.SubElement(root, \"item\")\n",
        "            item.set('bbox', str(bbox))\n",
        "            item.set('confidence', str(confidence))\n",
        "            item.text = text\n",
        "\n",
        "    tree = ET.ElementTree(root)\n",
        "    tree.write(xml_path, encoding=\"utf-8\", xml_declaration=True)\n",
        "\n",
        "def extract_specific_info_from_xml(xml_path, keywords, text_limits):\n",
        "    \"\"\"Extracts specific information based on predefined keywords from an XML file.\"\"\"\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "    items = list(root.findall('item'))\n",
        "    pairs = {}\n",
        "    current_key = None\n",
        "    current_text = []\n",
        "    current_limit = None\n",
        "\n",
        "    normalized_keywords = {keyword.lower(): keyword for keyword in keywords}\n",
        "\n",
        "    for item in items:\n",
        "        text = item.text or \"\"\n",
        "        normalized_text = text.lower().strip()\n",
        "\n",
        "        if any(normalized_text.startswith(keyword) for keyword in normalized_keywords):\n",
        "            if current_key:\n",
        "                formatted_text = ' '.join(current_text).strip()\n",
        "                if current_limit is not None:\n",
        "                    formatted_text = formatted_text[:current_limit]\n",
        "                pairs[current_key] = formatted_text\n",
        "            current_key = normalized_keywords.get(normalized_text, text.strip())\n",
        "            current_text = []\n",
        "            current_limit = text_limits.get(current_key, None)\n",
        "        elif current_key:\n",
        "            current_text.append(text.strip())\n",
        "\n",
        "    if current_key:\n",
        "        formatted_text = ' '.join(current_text).strip()\n",
        "        if current_limit is not None:\n",
        "            formatted_text = formatted_text[:current_limit]\n",
        "        pairs[current_key] = formatted_text\n",
        "\n",
        "    return pairs\n",
        "\n",
        "def main():\n",
        "    start_time = time.time()  # Start timing here\n",
        "\n",
        "    pdf_path = \"4.pdf\"\n",
        "    xml_path = \"output.xml\"\n",
        "    keywords = [\"Fastighetsägare\", \"Namn\", \"Postnr och ort\", \"Fastighetsbeteckning\", \"Anläggare av ledning\"]\n",
        "    text_limits = {\"Anläggare av ledning\": 41}  # Limit text for \"Anläggare av ledning\"\n",
        "\n",
        "    extract_text_to_xml(pdf_path, xml_path)\n",
        "    info = extract_specific_info_from_xml(xml_path, keywords, text_limits)  # Process and display information\n",
        "\n",
        "    for key in keywords:\n",
        "        value = info.get(key, \"\")  # Use get to handle missing keywords gracefully\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Total processing time: {elapsed_time} seconds\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHFTA6KyAySk",
        "outputId": "1533cc42-4fc2-46a6-ff5d-928b03493314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        }
      ]
    }
  ]
}