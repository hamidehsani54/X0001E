{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7-i04KaKpp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4baed5fc-dfef-48c7-9fb3-b01e8925712c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 3s (1,466 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.4 [186 kB]\n",
            "Fetched 186 kB in 2s (117 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 121965 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.4) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.4) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (9.4.0)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr-swe\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 2,232 kB of archives.\n",
            "After this operation, 4,182 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-swe all 1:4.00~git30-7274cfa-1.1 [2,232 kB]\n",
            "Fetched 2,232 kB in 3s (736 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-swe.\n",
            "(Reading database ... 121995 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-swe_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-swe (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-swe (1:4.00~git30-7274cfa-1.1) ...\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.4-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jiwer\n",
            "  Downloading jiwer-3.0.4-py3-none-any.whl (21 kB)\n",
            "Collecting PyMuPDFb==1.24.3 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
            "  Downloading rapidfuzz-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, PyMuPDFb, PyMuPDF, jiwer\n",
            "Successfully installed PyMuPDF-1.24.4 PyMuPDFb-1.24.3 jiwer-3.0.4 rapidfuzz-3.9.1\n"
          ]
        }
      ],
      "source": [
        "!apt-get install tesseract-ocr -y\n",
        "!pip install pytesseract\n",
        "!apt-get install poppler-utils -y\n",
        "!pip install pdf2image\n",
        "!apt-get install tesseract-ocr-swe\n",
        "!pip install PyMuPDF jiwer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "import os\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Remove invalid XML characters from the text.\n",
        "    \"\"\"\n",
        "    # Regex to match invalid XML characters\n",
        "    invalid_xml_chars = re.compile(u'[\\u0000-\\u0008\\u000B-\\u000C\\u000E-\\u001F]')\n",
        "    return invalid_xml_chars.sub('', text)\n",
        "\n",
        "pdf_path = '2.pdf'\n",
        "xml_file = os.path.splitext(pdf_path)[0] + '.xml'\n",
        "\n",
        "# Root element of the XML\n",
        "root = ET.Element(\"Document\")\n",
        "\n",
        "# Convert PDF to list of images\n",
        "images = convert_from_path(pdf_path)\n",
        "\n",
        "for i, image in enumerate(images):\n",
        "    # Perform OCR\n",
        "    text = pytesseract.image_to_string(image, lang='swe')\n",
        "\n",
        "    # Clean the OCR text\n",
        "    clean_text_data = clean_text(text)\n",
        "\n",
        "    # Create a 'Page' element for each page\n",
        "    page_element = ET.SubElement(root, \"Page\", number=str(i+1))\n",
        "\n",
        "    # Split text into lines\n",
        "    lines = clean_text_data.split('\\n')\n",
        "\n",
        "    # Add each line to the 'Page' element\n",
        "    for line_num, line in enumerate(lines):\n",
        "        line_element = ET.SubElement(page_element, \"Line\", number=str(line_num+1))\n",
        "        line_element.text = line\n",
        "\n",
        "# Create an ElementTree object from the root element\n",
        "tree = ET.ElementTree(root)\n",
        "\n",
        "# Write the XML to file, using the generated filename\n",
        "tree.write(xml_file, encoding=\"utf-8\", xml_declaration=True)\n",
        "\n",
        "print(f\"The program is done, please check the directory! {xml_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBgKv3oXE_bF",
        "outputId": "a47c8db0-e08a-4f0a-81f0-be8186122173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The program is done, please check the directory! 2.xml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "import re\n",
        "import os\n",
        "from jiwer import wer, cer\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Remove invalid XML characters from the text.\n",
        "    \"\"\"\n",
        "    invalid_xml_chars = re.compile(u'[\\u0000-\\u0008\\u000B-\\u000C\\u000E-\\u001F]')\n",
        "    return invalid_xml_chars.sub('', text)\n",
        "\n",
        "def process_file_pair(pdf_path, ground_truth_path):\n",
        "    \"\"\"\n",
        "    Convert PDF to images, perform OCR, and calculate WER and CER against ground truth text.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        images = convert_from_path(pdf_path)\n",
        "        all_text = []\n",
        "\n",
        "        for image in images:\n",
        "            text = pytesseract.image_to_string(image, lang='swe')\n",
        "            clean_text_data = clean_text(text)\n",
        "            all_text.append(clean_text_data)\n",
        "\n",
        "        ocr_output_text = '\\n'.join(all_text)\n",
        "\n",
        "        with open(ground_truth_path, 'r', encoding='utf-8') as gt_file:\n",
        "            ground_truth_text = gt_file.read()\n",
        "\n",
        "        calculated_wer = wer(ground_truth_text, ocr_output_text)\n",
        "        calculated_cer = cer(ground_truth_text, ocr_output_text)\n",
        "\n",
        "        print(f\"Processing {pdf_path}...\")\n",
        "        print(f\"WER: {calculated_wer}\")\n",
        "        print(f\"CER: {calculated_cer}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdf_path}: {str(e)}\")\n",
        "\n",
        "def get_file_pairs(directory):\n",
        "    \"\"\"\n",
        "    Returns a list of (pdf_path, txt_path) tuples from the directory.\n",
        "    \"\"\"\n",
        "    pdf_files = [f for f in os.listdir(directory) if f.lower().endswith('.pdf')]\n",
        "    file_pairs = [(os.path.join(directory, f), os.path.join(directory, f.replace('.pdf', '.txt')))\n",
        "                  for f in pdf_files if os.path.exists(os.path.join(directory, f.replace('.pdf', '.txt')))]\n",
        "    return file_pairs\n",
        "\n",
        "def main():\n",
        "    directory_path = 'text/'\n",
        "    file_pairs = get_file_pairs(directory_path)\n",
        "\n",
        "    if not file_pairs:\n",
        "        print(\"No valid file pairs found.\")\n",
        "        return\n",
        "\n",
        "    for pdf_path, txt_path in file_pairs:\n",
        "        process_file_pair(pdf_path, txt_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoiywPbwTDs6",
        "outputId": "5410d3eb-3876-43b4-a0cb-7faaba8cd58e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing text/2EDEPZ4VHTLPTWSZR6FAVUJ3B2ZVSIPS.pdf...\n",
            "WER: 0.019417475728155338\n",
            "CER: 0.009210526315789473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import re\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Remove invalid characters from the text.\n",
        "    \"\"\"\n",
        "    invalid_chars = re.compile(u'[\\u0000-\\u0008\\u000B-\\u000C\\u000E-\\u001F]')\n",
        "    return invalid_chars.sub('', text)\n",
        "\n",
        "def process_pdf(pdf_path):\n",
        "    # Generate txt filename by replacing the PDF extension with txt\n",
        "    txt_file = os.path.splitext(pdf_path)[0] + '.txt'\n",
        "\n",
        "    try:\n",
        "        # Convert PDF to list of images\n",
        "        images = convert_from_path(pdf_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to convert {pdf_path} to images: {e}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        with open(txt_file, 'w', encoding='utf-8') as file:\n",
        "            for i, image in enumerate(images):\n",
        "                # Perform OCR\n",
        "                text = pytesseract.image_to_string(image, lang='swe')\n",
        "\n",
        "                # Clean the OCR text\n",
        "                clean_text_data = clean_text(text)\n",
        "\n",
        "                # Write each page's text to the TXT file\n",
        "                file.write(f\"Page {i+1}\\n{clean_text_data}\\n\")\n",
        "                file.write(\"\\n\")  # Add a page break in the text file\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing to file {txt_file}: {e}\")\n",
        "    else:\n",
        "        print(f\"The text file {txt_file} has been created successfully.\")\n",
        "\n",
        "directory = 'text/'\n",
        "pdf_files = glob.glob(os.path.join(directory, '*.pdf'))\n",
        "for pdf_file in pdf_files:\n",
        "    process_pdf(pdf_file)\n"
      ],
      "metadata": {
        "id": "s-TaHTogE83G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting metadata from the PDF based on keywords\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Function to remove invalid XML characters\n",
        "def clean_text(text):\n",
        "    invalid_xml_chars = re.compile(u'[\\u0000-\\u0008\\u000B-\\u000C\\u000E-\\u001F]')\n",
        "    return invalid_xml_chars.sub('', text)\n",
        "\n",
        "def preprocess_image(image):\n",
        "    \"\"\"Apply image preprocessing steps to improve OCR accuracy.\"\"\"\n",
        "    # Convert image to grayscale\n",
        "    gray_image = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n",
        "    # Apply thresholding to binarize the image\n",
        "    _, thresh_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    # Optionally apply dilation to close gaps between letters; adjust kernel size as needed\n",
        "    kernel = np.ones((2,2), np.uint8)\n",
        "    dilated_image = cv2.dilate(thresh_image, kernel, iterations=1)\n",
        "    return dilated_image\n",
        "\n",
        "def print_first_keywords_and_values(xml_root, keywords):\n",
        "    \"\"\"Print the first occurrence of keywords and their values from an XML root.\"\"\"\n",
        "    # Initialize a set to track which keywords have been printed\n",
        "    printed_keywords = set()\n",
        "\n",
        "    for item in xml_root.findall('item'):\n",
        "        item_text = item.text or ''\n",
        "        for keyword in keywords:\n",
        "            if keyword not in printed_keywords and keyword.lower() in item_text.lower():\n",
        "                value = item_text.split(keyword)[-1].strip()\n",
        "                print(f\"{keyword}: {value}\")\n",
        "                printed_keywords.add(keyword)\n",
        "                break  # Break the loop after printing the first occurrence\n",
        "\n",
        "pdf_path = '3.pdf'\n",
        "xml_file = os.path.splitext(pdf_path)[0] + '_output.xml'\n",
        "images = convert_from_path(pdf_path)\n",
        "\n",
        "# Perform OCR on each image and save the text in the XML structure\n",
        "root = ET.Element(\"root\")\n",
        "for image in images:\n",
        "    processed_image = preprocess_image(image)\n",
        "    text = pytesseract.image_to_string(processed_image, lang='swe', config='--psm 6')\n",
        "    clean_text_data = clean_text(text)\n",
        "\n",
        "    # Split the cleaned text into lines and then add each line as an item to the XML root\n",
        "    for line in clean_text_data.split('\\n'):\n",
        "        if line.strip():  # Skip empty lines\n",
        "            item = ET.SubElement(root, \"item\")\n",
        "            item.text = line.strip()\n",
        "\n",
        "# Write the XML to a file\n",
        "tree = ET.ElementTree(root)\n",
        "tree.write(xml_file, encoding=\"utf-8\", xml_declaration=True)\n",
        "print(f\"The OCR process is complete, see the generated XML file: {xml_file}\")\n",
        "\n",
        "# Define the keywords to search for\n",
        "keywords = [\n",
        "    \"Fastighetsägare\", \"Namn\", \"Adress\", \"Postnr och ort\",\n",
        "    \"Fastighetsbeteckning\", \"Anläggare av ledning\"\n",
        "]\n",
        "\n",
        "# Parse the XML file just created and search for the keywords\n",
        "try:\n",
        "    # Parse the XML file\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Print the first occurrence of keywords and values\n",
        "    print_first_keywords_and_values(root, keywords)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during XML parsing: {e}\")\n"
      ],
      "metadata": {
        "id": "m1o9_NT-SMqb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate the time duration\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Function to remove invalid XML characters\n",
        "def clean_text(text):\n",
        "    invalid_xml_chars = re.compile(u'[\\u0000-\\u0008\\u000B-\\u000C\\u000E-\\u001F]')\n",
        "    return invalid_xml_chars.sub('', text)\n",
        "\n",
        "def preprocess_image(image):\n",
        "    \"\"\"Apply image preprocessing steps to improve OCR accuracy.\"\"\"\n",
        "    # Convert image to grayscale\n",
        "    gray_image = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n",
        "    # Apply thresholding to binarize the image\n",
        "    _, thresh_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    # Optionally apply dilation to close gaps between letters; adjust kernel size as needed\n",
        "    kernel = np.ones((2,2), np.uint8)\n",
        "    dilated_image = cv2.dilate(thresh_image, kernel, iterations=1)\n",
        "    return dilated_image\n",
        "\n",
        "def print_first_keywords_and_values(xml_root, keywords):\n",
        "    \"\"\"Print the first occurrence of keywords and their values from an XML root.\"\"\"\n",
        "    printed_keywords = set()\n",
        "    for item in xml_root.findall('item'):\n",
        "        item_text = item.text or ''\n",
        "        for keyword in keywords:\n",
        "            if keyword not in printed_keywords and keyword.lower() in item_text.lower():\n",
        "                value = item_text.split(keyword)[-1].strip()\n",
        "                print(f\"{keyword}: {value}\")\n",
        "                printed_keywords.add(keyword)\n",
        "                break\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "pdf_path = '4.pdf'\n",
        "xml_file = os.path.splitext(pdf_path)[0] + '_output.xml'\n",
        "\n",
        "# Convert PDF pages to images\n",
        "images = convert_from_path(pdf_path)\n",
        "\n",
        "# Perform OCR on each image and save the text in the XML structure\n",
        "root = ET.Element(\"root\")\n",
        "for image in images:\n",
        "    processed_image = preprocess_image(image)\n",
        "    text = pytesseract.image_to_string(processed_image, lang='swe', config='--psm 6')\n",
        "    clean_text_data = clean_text(text)\n",
        "    for line in clean_text_data.split('\\n'):\n",
        "        if line.strip():\n",
        "            item = ET.SubElement(root, \"item\")\n",
        "            item.text = line.strip()\n",
        "\n",
        "tree = ET.ElementTree(root)\n",
        "tree.write(xml_file, encoding=\"utf-8\", xml_declaration=True)\n",
        "print(f\"The OCR process is complete, see the generated XML file: {xml_file}\")\n",
        "\n",
        "keywords = [\n",
        "    \"Fastighetsägare\", \"Namn\", \"Adress\", \"Postnr och ort\",\n",
        "    \"Fastighetsbeteckning\", \"Anläggare av ledning\"\n",
        "]\n",
        "\n",
        "try:\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    print_first_keywords_and_values(root, keywords)\n",
        "except Exception as e:\n",
        "    print(f\"Error during XML parsing: {e}\")\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Total processing time: {elapsed_time} seconds\")\n"
      ],
      "metadata": {
        "id": "0TNy_phpAblE",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "import os\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Remove invalid XML characters from the text.\n",
        "    \"\"\"\n",
        "    invalid_xml_chars = re.compile(u'[\\u0000-\\u0008\\u000B-\\u000C\\u000E-\\u001F]')\n",
        "    return invalid_xml_chars.sub('', text)\n",
        "\n",
        "current_directory = '2.pdf'\n",
        "\n",
        "# Directory to store the XML files\n",
        "xml_directory = os.path.join(current_directory, 'ALL_XML')\n",
        "\n",
        "# Create the XML directory if it doesn't exist\n",
        "if not os.path.exists(xml_directory):\n",
        "    os.makedirs(xml_directory)\n",
        "\n",
        "# List all PDF files\n",
        "pdf_files = [f for f in os.listdir(current_directory) if f.endswith('.pdf')]\n",
        "total_files = len(pdf_files)\n",
        "processed_files = 0\n",
        "\n",
        "# Function to update and display progress\n",
        "def update_progress(processed, total):\n",
        "    progress = (processed / total) * 100\n",
        "    print(f\"Processing: {processed}/{total} files ({progress:.2f}%) complete\", end='\\r')\n",
        "\n",
        "# Loop through all PDF files\n",
        "for filename in pdf_files:\n",
        "    pdf_path = os.path.join(current_directory, filename)\n",
        "\n",
        "    # Generate XML filename and store it in the 'ALL_XML' folder\n",
        "    xml_file = os.path.join(xml_directory, os.path.splitext(filename)[0] + '.xml')\n",
        "\n",
        "    # XML root element\n",
        "    root = ET.Element(\"Document\")\n",
        "\n",
        "    # Convert PDF to images\n",
        "    images = convert_from_path(pdf_path)\n",
        "\n",
        "    for i, image in enumerate(images):\n",
        "        # Perform OCR\n",
        "        text = pytesseract.image_to_string(image, lang='swe')\n",
        "        # Clean the text\n",
        "        clean_text_data = clean_text(text)\n",
        "        # Page element\n",
        "        page_element = ET.SubElement(root, \"Page\", number=str(i+1))\n",
        "        # Split text into lines and add to 'Page' element\n",
        "        for line_num, line in enumerate(clean_text_data.split('\\n')):\n",
        "            line_element = ET.SubElement(page_element, \"Line\", number=str(line_num+1))\n",
        "            line_element.text = line\n",
        "\n",
        "    # Write XML file\n",
        "    tree = ET.ElementTree(root)\n",
        "    tree.write(xml_file, encoding=\"utf-8\", xml_declaration=True)\n",
        "\n",
        "    # Update progress\n",
        "    processed_files += 1\n",
        "    update_progress(processed_files, total_files)\n",
        "\n",
        "print(\"\\nProcessing complete. Please check the 'ALL_XML' directory!\")\n"
      ],
      "metadata": {
        "id": "5l6ZHbivc-VY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}